{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vdudiev/text-recognising/blob/main/%D0%A0%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5%D0%A2%D0%B5%D0%BA%D1%81%D1%82%D0%B0%D0%9D%D0%B0%D0%9A%D0%B0%D1%80%D1%82%D0%B8%D0%BD%D0%BA%D0%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d97PKUmPh9Uz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c6c464-441d-4198-9cbd-7ee0a6494c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "!pip3 install -q idx2numpy\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow  as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import idx2numpy\n",
        "from google.colab.patches import cv2_imshow\n",
        "from typing import *\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgOpXNWDiYNq"
      },
      "outputs": [],
      "source": [
        "def cnn_print_digit(d):\n",
        "    print(d.shape)\n",
        "    for x in range(28):\n",
        "        s = \"\"\n",
        "        for y in range(28):\n",
        "            s += \"{0:.1f} \".format(d[28 * y + x])\n",
        "        print(s)\n",
        "\n",
        "\n",
        "def cnn_print_digit_2d(d):\n",
        "    print(d.shape)\n",
        "    for y in range(d.shape[0]):\n",
        "        s = \"\"\n",
        "        for x in range(d.shape[1]):\n",
        "            s += \"{0:.1f} \".format(d[x][y])\n",
        "        print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BrMFdg3ib7p"
      },
      "outputs": [],
      "source": [
        "emnist_labels = [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74,\n",
        "                 75, 76,77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 99, 100,\n",
        "                 101, 102, 103, 104, 105, 106,107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
        "                 117, 118, 119, 120, 121, 122]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6MnnaCfjqBg"
      },
      "outputs": [],
      "source": [
        "def text_from_img_writer_model():\n",
        "    model = Sequential([])\n",
        "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=(28, 28, 1), activation='relu'))\n",
        "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(len(emnist_labels), activation=\"softmax\"))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUijJ6Kw1i7p"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihgUrekfnyYs"
      },
      "outputs": [],
      "source": [
        "def train_model(model):\n",
        "    t_start = time.time()\n",
        "    X_train = idx2numpy.convert_from_file('/content/drive/MyDrive/Colab Notebooks/gzip/emnistByclassTrainImagesIdx3Ubyte')\n",
        "    y_train = idx2numpy.convert_from_file('/content/drive/MyDrive/Colab Notebooks/gzip/emnistByclassTrainLabelsIdx1Ubyte')\n",
        "\n",
        "    X_test = idx2numpy.convert_from_file('/content/drive/MyDrive/Colab Notebooks/gzip/emnistByclassTestImagesIdx3Ubyte')\n",
        "    y_test = idx2numpy.convert_from_file('/content/drive/MyDrive/Colab Notebooks/gzip/emnistByclassTestLabelsIdx1Ubyte')\n",
        "\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], 28, 28, 1))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], 28, 28, 1))\n",
        "\n",
        "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels))\n",
        "\n",
        "    # Test:\n",
        "    k = 10\n",
        "    X_train = X_train[:X_train.shape[0] // k]\n",
        "    y_train = y_train[:y_train.shape[0] // k]\n",
        "    X_test = X_test[:X_test.shape[0] // k]\n",
        "    y_test = y_test[:y_test.shape[0] // k]\n",
        "\n",
        "    # Normalize\n",
        "    X_train = X_train.astype(np.float32)\n",
        "    X_train /= 255.0\n",
        "    X_test = X_test.astype(np.float32)\n",
        "    X_test /= 255.0\n",
        "\n",
        "    x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels))\n",
        "    y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels))\n",
        "\n",
        "    \n",
        "    # Set a learning rate reduction\n",
        "    learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5,\n",
        "                                                                min_lr=0.00001)\n",
        "\n",
        "    model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction],\n",
        "              batch_size=64, epochs=30)\n",
        "    print(\"Training done, dT:\", time.time() - t_start)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1db1UC9pTGK"
      },
      "outputs": [],
      "source": [
        "def predict(model, image_file):\n",
        "    img = keras.preprocessing.image.load_img(image_file, target_size=(28, 28), color_mode='grayscale')\n",
        "    predict_img(model, img)\n",
        "\n",
        "\n",
        "def predict_img(model, img):\n",
        "    img_arr = np.expand_dims(img, axis=0)\n",
        "    img_arr = 1 - img_arr / 255.0\n",
        "    img_arr[0] = np.rot90(img_arr[0], 3)\n",
        "    img_arr[0] = np.fliplr(img_arr[0])\n",
        "    img_arr = img_arr.reshape((1, 28, 28, 1))\n",
        "\n",
        "    predict = model.predict([img_arr])\n",
        "    result = np.argmax(predict, axis=1)\n",
        "    return chr(emnist_labels[result[0]])\n",
        "\n",
        "\n",
        "def letters_fetch(image_file: str, out_size=28):\n",
        "    img = cv2.imread(image_file)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "    img_erode = cv2.erode(thresh, np.ones((3, 3), np.uint8), iterations=1)\n",
        "\n",
        "    # получить контуры\n",
        "    contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "    output = img.copy()\n",
        "\n",
        "    letters = []\n",
        "    for idx, contour in enumerate(contours):\n",
        "        (x, y, w, h) = cv2.boundingRect(contour)\n",
        "        if hierarchy[0][idx][3] == 0:\n",
        "            cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
        "            letter_crop = gray[y:y + h, x:x + w]\n",
        "\n",
        "            # Изменить размер холста для письма до квадратного\n",
        "            size_max = max(w, h)\n",
        "            letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
        "            if w > h:\n",
        "                # Увеличить изображение сверху вниз\n",
        "                y_pos = size_max // 2 - h // 2\n",
        "                letter_square[y_pos:y_pos + h, 0:w] = letter_crop\n",
        "            elif w < h:\n",
        "                x_pos = size_max // 2 - w // 2\n",
        "                letter_square[0:h, x_pos:x_pos + w] = letter_crop\n",
        "            else:\n",
        "                letter_square = letter_crop\n",
        "\n",
        "            # Измените размер буквы на 28x28 и добавьте букву и ее координату X\n",
        "            letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA)))\n",
        "\n",
        "    # Сортировка массива на месте по координате X\n",
        "    letters.sort(key=lambda x: x[0], reverse=False)\n",
        "\n",
        "    # cv2_imshow(img)\n",
        "    cv2_imshow(img_erode)\n",
        "    cv2_imshow(output)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    return letters\n",
        "\n",
        "\n",
        "def img_to_concole(model: Any, image_file: str):\n",
        "    letters = letters_fetch(image_file)\n",
        "    s_out = \"\"\n",
        "    for i in range(len(letters)):\n",
        "        dn = letters[i + 1][0] - letters[i][0] - letters[i][1] if i < len(letters) - 1 else 0\n",
        "        s_out += predict_img(model, letters[i][2])\n",
        "        if (dn > letters[i][1] / 4):\n",
        "            s_out += ' '\n",
        "    return s_out\n",
        "\n",
        "\n",
        "\n",
        "# model = text_from_img_writer_model()\n",
        "x_test_for_show = idx2numpy.convert_from_file('/content/drive/MyDrive/Colab Notebooks/gzip/emnistByclassTestImagesIdx3Ubyte')\n",
        "y_test_for_show = idx2numpy.convert_from_file('/content/drive/MyDrive/Colab Notebooks/gzip/emnistByclassTestLabelsIdx1Ubyte')\n",
        "\n",
        "x_test_for_show = np.reshape(x_test_for_show, (x_test_for_show.shape[0], 28, 28, 1))\n",
        "# Test:\n",
        "k = 10\n",
        "x_test_for_show = x_test_for_show[:x_test_for_show.shape[0] // k]\n",
        "y_test_for_show = y_test_for_show[:y_test_for_show.shape[0] // k]\n",
        "\n",
        "    # Normalize\n",
        "x_test_for_show = x_test_for_show.astype(np.float32)\n",
        "x_test_for_show /= 255.0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(10, 5))\n",
        "\n",
        "# for i in range(100) :\n",
        "#     plt.subplot(10, 10, i+1)\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "#     plt.imshow(X_test_for_show[i], cmap=plt.cm.binary)\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     model = text_from_img_writer_model()\n",
        "#     train_model(model)\n",
        "#     model.save('text_from_img_writer_model.h5')\n",
        "\n",
        "#     model = keras.models.load_model('text_from_img_writer_model.h5')\n",
        "#     s_out = img_to_concole(model, \"hello.png\")\n",
        "#     print(s_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение модели"
      ],
      "metadata": {
        "id": "Dm_YJExOMK9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Если модель не сохранена на диске - заупустить данный блок\n",
        "model = text_from_img_writer_model()\n",
        "train_model(model)\n",
        "model.save('text_from_img_writer_model.h5')"
      ],
      "metadata": {
        "id": "YNIB2OgGMKRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Еслимодель сохранена на диске - запустить данный блок \n",
        "model_from_rep = tf.keras.models.load_model( 'text_writer_model_2.h5' )"
      ],
      "metadata": {
        "id": "0kj4wF1oxLO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result_for_show = predict_img(model_from_rep,X_test_for_show)\n",
        "\n",
        "\n",
        "# print(result_for_show)\n",
        "\n",
        "\n",
        "s_out = img_to_concole(model_from_rep, \"/content/drive/MyDrive/Colab Notebooks/hello_world_test.png\")\n",
        "print(\"надпись на картинке:\",s_out)"
      ],
      "metadata": {
        "id": "4yGJH8h0j20B"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "РаспознаваниеТекстаНаКартинке.ipynb",
      "provenance": [],
      "mount_file_id": "1lwcitcTgOBFCSGosJsH9JKXNXbAio1pe",
      "authorship_tag": "ABX9TyO3VmI9szEdb+uWaR3J+fU/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}